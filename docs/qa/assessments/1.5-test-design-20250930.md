# Test Design: Story 1.5 - Testing Infrastructure & Environment Validation

**Date:** 2025-09-30
**Designer:** Quinn (Test Architect)
**Story:** 1.5 - Testing Infrastructure & Environment Validation

## Test Strategy Overview

- **Total Test Scenarios:** 45
- **Unit Tests:** 8 (18%)
- **Integration Tests:** 27 (60%)
- **E2E Tests:** 3 (7%)
- **Manual Validation:** 7 (15%)
- **Priority Distribution:** P0: 18, P1: 15, P2: 9, P3: 3

**Rationale for Distribution:**

This story creates test infrastructure, so traditional test pyramid doesn't apply. Most scenarios are **integration tests** verifying framework components work together. **Manual validation** is necessary due to circular dependency (can't test test infrastructure with itself). **Unit tests** validate specific utilities. **E2E tests** verify end-to-end test workflows.

## Test Scenarios by Acceptance Criteria

### AC1: Comprehensive Testing Framework Setup

**Description:** pytest 7.4+, Jest 29+, React Testing Library, Playwright, Coverage reporting with 80%+ target

#### Scenarios

| ID             | Level       | Priority | Test                                      | Justification                                     | Mitigates Risks          |
| -------------- | ----------- | -------- | ----------------------------------------- | ------------------------------------------------- | ------------------------ |
| 1.5-INT-001    | Integration | P0       | pytest discovers tests in apps/api/tests  | Verify test discovery pattern works               | TECH-001 (Circular)      |
| 1.5-INT-002    | Integration | P0       | pytest async tests execute correctly      | Verify pytest-asyncio configuration               | TECH-003 (Async)         |
| 1.5-UNIT-001   | Unit        | P0       | pytest fixture provides test database     | Verify database fixture isolation                 | DATA-001 (Isolation)     |
| 1.5-INT-003    | Integration | P0       | Vitest runs existing tests from Story 1.4 | Verify frontend testing still works after changes | TECH-001 (Circular)      |
| 1.5-INT-004    | Integration | P1       | Vitest coverage report generates          | Verify coverage.py and vitest coverage configured | TECH-001 (Circular)      |
| 1.5-INT-005    | Integration | P0       | Playwright installs browsers successfully | Verify browser installation works cross-platform  | TECH-004, OPS-001        |
| 1.5-E2E-001    | E2E         | P1       | Playwright runs example health check test | Verify E2E test execution end-to-end              | TECH-001 (Circular)      |
| 1.5-INT-006    | Integration | P1       | Coverage threshold enforced (80%)         | Verify coverage gates work                        | TECH-001 (Circular)      |
| 1.5-MANUAL-001 | Manual      | P0       | Playwright browsers work on all platforms | Validate Windows WSL2, macOS, Linux               | OPS-001 (Cross-platform) |

**Coverage Summary for AC1:**

- ✅ pytest installation and configuration
- ✅ pytest async support
- ✅ Vitest backward compatibility
- ✅ Playwright installation and browser setup
- ✅ Coverage reporting for both frontend and backend
- ✅ Cross-platform validation

---

### AC2: Mock Services and Test Data Strategy

**Description:** Mock LLM providers (Claude, OpenAI, OLLAMA), Mock MCP server, Test database with seed data, External API mocking

#### Scenarios

| ID             | Level       | Priority | Test                                           | Justification                                         | Mitigates Risks     |
| -------------- | ----------- | -------- | ---------------------------------------------- | ----------------------------------------------------- | ------------------- |
| 1.5-UNIT-002   | Unit        | P0       | Claude API mock returns completion response    | Verify mock matches real API response format          | TECH-002 (Mock)     |
| 1.5-UNIT-003   | Unit        | P0       | Claude API mock handles streaming responses    | Verify streaming format matches real API              | TECH-002 (Mock)     |
| 1.5-UNIT-004   | Unit        | P1       | OpenAI API mock returns expected format        | Verify fallback provider mock accuracy                | TECH-002 (Mock)     |
| 1.5-UNIT-005   | Unit        | P1       | OLLAMA mock responds to local requests         | Verify offline development scenario mock              | TECH-002 (Mock)     |
| 1.5-INT-007    | Integration | P0       | Mock MCP server simulates file sync operations | Verify MCP protocol mock works                        | TECH-002 (Mock)     |
| 1.5-INT-008    | Integration | P0       | Mock MCP server simulates workflow transitions | Verify workflow state mock accuracy                   | TECH-002 (Mock)     |
| 1.5-INT-009    | Integration | P1       | Mock MCP server simulates error scenarios      | Verify error simulation (timeout, connection failure) | TECH-002 (Mock)     |
| 1.5-INT-010    | Integration | P0       | Test database seeds Client hierarchy fixtures  | Verify realistic test data loads                      | DATA-002 (Fixtures) |
| 1.5-INT-011    | Integration | P0       | Test database seeds BMAD workflow samples      | Verify workflow state fixtures                        | DATA-002 (Fixtures) |
| 1.5-INT-012    | Integration | P1       | Test database seeds document metadata          | Verify document test data                             | DATA-002 (Fixtures) |
| 1.5-INT-013    | Integration | P0       | MSW handlers work for frontend (from 1.4)      | Verify existing MSW setup still functional            | TECH-001 (Circular) |
| 1.5-INT-014    | Integration | P1       | Wiremock (or alternative) mocks backend APIs   | Verify backend API mocking infrastructure             | TECH-005 (Wiremock) |
| 1.5-MANUAL-002 | Manual      | P0       | Compare mock responses to real API docs        | Manual validation of mock accuracy                    | TECH-002 (Mock)     |

**Coverage Summary for AC2:**

- ✅ All LLM provider mocks (Claude, OpenAI, OLLAMA)
- ✅ Mock MCP server with file sync, workflow, and error simulation
- ✅ Test database with comprehensive seed data
- ✅ Frontend API mocking (MSW) verification
- ✅ Backend API mocking infrastructure
- ✅ Manual validation against real API documentation

---

### AC3: Test Environment Management

**Description:** docker-compose.test.yml, Separate test database, Test environment variables, CI/CD integration

#### Scenarios

| ID             | Level       | Priority | Test                                           | Justification                                  | Mitigates Risks    |
| -------------- | ----------- | -------- | ---------------------------------------------- | ---------------------------------------------- | ------------------ |
| 1.5-INT-015    | Integration | P0       | docker-compose.test.yml starts test services   | Verify isolated test environment launches      | DATA-001, OPS-002  |
| 1.5-INT-016    | Integration | P0       | Test database runs on port 5433 (not 5432)     | Verify test database isolation from dev        | DATA-001           |
| 1.5-INT-017    | Integration | P0       | Test database has pgvector extension loaded    | Verify test database matches dev configuration | DATA-001           |
| 1.5-INT-018    | Integration | P0       | Test database cleanup after test suite         | Verify automatic cleanup works                 | DATA-001           |
| 1.5-UNIT-006   | Unit        | P0       | .env.test loaded correctly in test environment | Verify test environment variables loaded       | -                  |
| 1.5-INT-019    | Integration | P1       | Test environment uses mock API endpoints       | Verify CLAUDE_API_URL points to mock           | TECH-002           |
| 1.5-INT-020    | Integration | P0       | Dev database never modified during tests       | Verify strict test/dev isolation               | DATA-001           |
| 1.5-INT-021    | Integration | P1       | CI/CD workflow runs pytest successfully        | Verify GitHub Actions pytest integration       | PERF-001           |
| 1.5-INT-022    | Integration | P1       | CI/CD workflow runs Vitest successfully        | Verify GitHub Actions Vitest integration       | PERF-001           |
| 1.5-INT-023    | Integration | P1       | CI/CD workflow runs Playwright successfully    | Verify GitHub Actions Playwright integration   | PERF-001           |
| 1.5-INT-024    | Integration | P0       | CI/CD caches Playwright browsers               | Verify browser cache reduces installation time | PERF-001, TECH-004 |
| 1.5-INT-025    | Integration | P1       | CI/CD generates and uploads coverage reports   | Verify coverage reporting in CI/CD             | TECH-001           |
| 1.5-MANUAL-003 | Manual      | P0       | CI/CD completes in <15 minutes                 | Measure baseline CI/CD execution time          | PERF-001           |

**Coverage Summary for AC3:**

- ✅ docker-compose.test.yml with isolated test services
- ✅ Test database on separate port (5433) with pgvector
- ✅ Test database cleanup and isolation verification
- ✅ Test environment variables (.env.test)
- ✅ CI/CD integration for all test frameworks
- ✅ CI/CD performance optimization (caching, parallelization)
- ✅ CI/CD time measurement

---

### AC4: Development Environment Validation

**Description:** Automated setup verification, Health checks, Integration test suite, Performance baseline

#### Scenarios

| ID             | Level       | Priority | Test                                             | Justification                                 | Mitigates Risks |
| -------------- | ----------- | -------- | ------------------------------------------------ | --------------------------------------------- | --------------- |
| 1.5-INT-026    | Integration | P0       | validate-setup.sh detects all required tools     | Verify automated environment validation       | OPS-001         |
| 1.5-INT-027    | Integration | P0       | validate-setup.sh checks Python 3.11.5+          | Verify Python version validation              | OPS-001         |
| 1.5-INT-028    | Integration | P0       | validate-setup.sh checks Node.js 18.17.0+        | Verify Node.js version validation             | OPS-001         |
| 1.5-INT-029    | Integration | P0       | validate-setup.sh checks Docker availability     | Verify Docker installation check              | OPS-001         |
| 1.5-INT-030    | Integration | P1       | validate-setup.sh detects port conflicts         | Verify port 5433 conflict detection           | OPS-002         |
| 1.5-E2E-002    | E2E         | P0       | Health check endpoint /api/v1/health returns 200 | Verify API health check works                 | -               |
| 1.5-INT-031    | Integration | P1       | Health check verifies database connectivity      | Verify health check includes database status  | -               |
| 1.5-INT-032    | Integration | P1       | Health check verifies Redis connectivity         | Verify health check includes Redis status     | -               |
| 1.5-E2E-003    | E2E         | P1       | Integration test: API to database round-trip     | Verify critical API+DB flow works             | DATA-001        |
| 1.5-MANUAL-004 | Manual      | P0       | Measure API response time baseline               | Establish performance baseline for monitoring | PERF-001        |

**Coverage Summary for AC4:**

- ✅ Automated environment validation script
- ✅ Version checks for Python, Node.js, Docker
- ✅ Port conflict detection
- ✅ Health check endpoints for all services
- ✅ Integration test for critical flows
- ✅ Performance baseline measurement

---

### AC5: Fallback and Recovery Procedures

**Description:** Docker recovery, Database reset, Test cleanup, Alternative installation methods

#### Scenarios

| ID             | Level       | Priority | Test                                         | Justification                            | Mitigates Risks |
| -------------- | ----------- | -------- | -------------------------------------------- | ---------------------------------------- | --------------- |
| 1.5-INT-033    | Integration | P1       | docker-recovery.sh resets Docker environment | Verify Docker reset works                | OPS-001         |
| 1.5-INT-034    | Integration | P1       | db-reset.sh resets test database             | Verify database reset and migration      | DATA-001        |
| 1.5-INT-035    | Integration | P1       | test-cleanup.sh cleans test artifacts        | Verify test cleanup script works         | DATA-001        |
| 1.5-UNIT-007   | Unit        | P2       | Recovery scripts have execute permissions    | Verify script permissions set correctly  | OPS-003         |
| 1.5-MANUAL-005 | Manual      | P1       | Recovery scripts work on all platforms       | Validate cross-platform script execution | OPS-001         |
| 1.5-MANUAL-006 | Manual      | P2       | Alternative installation documented          | Verify manual installation docs complete | OPS-001         |

**Coverage Summary for AC5:**

- ✅ Docker environment recovery script
- ✅ Database reset and migration script
- ✅ Test cleanup script
- ✅ Script execution permissions
- ✅ Cross-platform script validation
- ✅ Alternative installation documentation

---

### AC6: Developer Onboarding with Testing Validation

**Description:** <10 minute setup, Test suite runs as verification, Documentation includes testing workflow, Setup success criteria

#### Scenarios

| ID             | Level       | Priority | Test                                         | Justification                            | Mitigates Risks |
| -------------- | ----------- | -------- | -------------------------------------------- | ---------------------------------------- | --------------- |
| 1.5-MANUAL-007 | Manual      | P0       | New developer setup completes in <10 minutes | Measure onboarding time on clean VM      | OPS-001         |
| 1.5-INT-036    | Integration | P0       | Test suite runs successfully after setup     | Verify onboarding verification works     | TECH-001        |
| 1.5-UNIT-008   | Unit        | P1       | Testing documentation covers all frameworks  | Verify docs/testing-guide.md complete    | BUS-001         |
| 1.5-INT-037    | Integration | P2       | README.md includes testing commands          | Verify README updated with test commands | BUS-001         |
| 1.5-INT-038    | Integration | P3       | Testing best practices documented            | Verify best practices doc exists         | BUS-001         |

**Coverage Summary for AC6:**

- ✅ <10 minute onboarding time measurement
- ✅ Test suite as onboarding verification
- ✅ Comprehensive testing documentation
- ✅ README updated with testing workflow
- ✅ Testing best practices documented

---

## Risk Coverage Matrix

Mapping test scenarios to identified risks:

| Risk ID  | Risk Description               | Test Scenarios Mitigating Risk                                                     |
| -------- | ------------------------------ | ---------------------------------------------------------------------------------- |
| TECH-001 | Circular dependency            | INT-001, INT-003, INT-004, INT-006, E2E-001, INT-013, INT-025, INT-036, MANUAL-001 |
| OPS-001  | Cross-platform inconsistencies | MANUAL-001, INT-026-030, INT-033, MANUAL-005, MANUAL-007                           |
| TECH-002 | Mock LLM service accuracy      | UNIT-002-005, INT-007-009, INT-019, MANUAL-002                                     |
| DATA-001 | Test database isolation        | UNIT-001, INT-015-018, INT-020, E2E-003, INT-034-035                               |
| PERF-001 | CI/CD exceeds 15 minutes       | INT-021-024, MANUAL-003, MANUAL-004                                                |
| TECH-003 | pytest async complexity        | INT-002                                                                            |
| TECH-004 | Playwright browser size        | INT-005, INT-024, MANUAL-001                                                       |
| OPS-002  | Docker port conflicts          | INT-015, INT-030                                                                   |
| DATA-002 | Test fixture staleness         | INT-010-012                                                                        |
| TECH-005 | Wiremock Java dependency       | INT-014                                                                            |
| OPS-003  | Script execution permissions   | UNIT-007                                                                           |
| BUS-001  | Testing documentation clarity  | UNIT-008, INT-037, INT-038                                                         |

**Coverage Assessment:**

- ✅ All 12 identified risks have test coverage
- ✅ Critical risks (TECH-001, OPS-001) have multiple test scenarios
- ✅ High risks have dedicated integration tests
- ✅ Medium/Low risks have appropriate unit or manual tests

---

## Test Scenarios by Level and Priority

### Unit Tests (8 scenarios)

| ID       | Priority | Test                                        |
| -------- | -------- | ------------------------------------------- |
| UNIT-001 | P0       | pytest fixture provides test database       |
| UNIT-002 | P0       | Claude API mock returns completion response |
| UNIT-003 | P0       | Claude API mock handles streaming responses |
| UNIT-004 | P1       | OpenAI API mock returns expected format     |
| UNIT-005 | P1       | OLLAMA mock responds to local requests      |
| UNIT-006 | P0       | .env.test loaded correctly                  |
| UNIT-007 | P2       | Recovery scripts have execute permissions   |
| UNIT-008 | P1       | Testing documentation covers all frameworks |

### Integration Tests (27 scenarios)

| ID      | Priority | Test                                           |
| ------- | -------- | ---------------------------------------------- |
| INT-001 | P0       | pytest discovers tests in apps/api/tests       |
| INT-002 | P0       | pytest async tests execute correctly           |
| INT-003 | P0       | Vitest runs existing tests from Story 1.4      |
| INT-004 | P1       | Vitest coverage report generates               |
| INT-005 | P0       | Playwright installs browsers successfully      |
| INT-006 | P1       | Coverage threshold enforced (80%)              |
| INT-007 | P0       | Mock MCP server simulates file sync operations |
| INT-008 | P0       | Mock MCP server simulates workflow transitions |
| INT-009 | P1       | Mock MCP server simulates error scenarios      |
| INT-010 | P0       | Test database seeds Client hierarchy fixtures  |
| INT-011 | P0       | Test database seeds BMAD workflow samples      |
| INT-012 | P1       | Test database seeds document metadata          |
| INT-013 | P0       | MSW handlers work for frontend (from 1.4)      |
| INT-014 | P1       | Wiremock (or alternative) mocks backend APIs   |
| INT-015 | P0       | docker-compose.test.yml starts test services   |
| INT-016 | P0       | Test database runs on port 5433                |
| INT-017 | P0       | Test database has pgvector extension loaded    |
| INT-018 | P0       | Test database cleanup after test suite         |
| INT-019 | P1       | Test environment uses mock API endpoints       |
| INT-020 | P0       | Dev database never modified during tests       |
| INT-021 | P1       | CI/CD workflow runs pytest successfully        |
| INT-022 | P1       | CI/CD workflow runs Vitest successfully        |
| INT-023 | P1       | CI/CD workflow runs Playwright successfully    |
| INT-024 | P0       | CI/CD caches Playwright browsers               |
| INT-025 | P1       | CI/CD generates and uploads coverage reports   |
| INT-026 | P0       | validate-setup.sh detects all required tools   |
| INT-027 | P0       | validate-setup.sh checks Python 3.11.5+        |
| INT-028 | P0       | validate-setup.sh checks Node.js 18.17.0+      |
| INT-029 | P0       | validate-setup.sh checks Docker availability   |
| INT-030 | P1       | validate-setup.sh detects port conflicts       |
| INT-031 | P1       | Health check verifies database connectivity    |
| INT-032 | P1       | Health check verifies Redis connectivity       |
| INT-033 | P1       | docker-recovery.sh resets Docker environment   |
| INT-034 | P1       | db-reset.sh resets test database               |
| INT-035 | P1       | test-cleanup.sh cleans test artifacts          |
| INT-036 | P0       | Test suite runs successfully after setup       |
| INT-037 | P2       | README.md includes testing commands            |
| INT-038 | P3       | Testing best practices documented              |

### E2E Tests (3 scenarios)

| ID      | Priority | Test                                             |
| ------- | -------- | ------------------------------------------------ |
| E2E-001 | P1       | Playwright runs example health check test        |
| E2E-002 | P0       | Health check endpoint /api/v1/health returns 200 |
| E2E-003 | P1       | Integration test: API to database round-trip     |

### Manual Validation (7 scenarios)

| ID         | Priority | Test                                         |
| ---------- | -------- | -------------------------------------------- |
| MANUAL-001 | P0       | Playwright browsers work on all platforms    |
| MANUAL-002 | P0       | Compare mock responses to real API docs      |
| MANUAL-003 | P0       | CI/CD completes in <15 minutes               |
| MANUAL-004 | P0       | Measure API response time baseline           |
| MANUAL-005 | P1       | Recovery scripts work on all platforms       |
| MANUAL-006 | P2       | Alternative installation documented          |
| MANUAL-007 | P0       | New developer setup completes in <10 minutes |

---

## Recommended Execution Order

### Phase 1: Foundation Validation (P0 Unit Tests)

**Run First - Fail Fast**

1. UNIT-001: pytest fixture provides test database
2. UNIT-002: Claude API mock returns completion response
3. UNIT-003: Claude API mock handles streaming responses
4. UNIT-006: .env.test loaded correctly

**Rationale:** Validate core building blocks before integration tests

### Phase 2: Framework Integration (P0 Integration Tests)

**Critical Path - Must Pass**

1. INT-001: pytest discovers tests
2. INT-002: pytest async tests execute
3. INT-003: Vitest runs existing tests
4. INT-005: Playwright installs browsers
5. INT-007: Mock MCP file sync
6. INT-008: Mock MCP workflow transitions
7. INT-010: Test database seeds Clients
8. INT-011: Test database seeds BMAD workflows
9. INT-013: MSW handlers work
10. INT-015: docker-compose.test.yml starts
11. INT-016: Test database on port 5433
12. INT-017: Test database has pgvector
13. INT-018: Test database cleanup
14. INT-020: Dev database never modified
15. INT-024: CI/CD caches browsers
16. INT-026-029: validate-setup.sh checks
17. INT-036: Test suite runs after setup

**Rationale:** Verify all frameworks work before advanced features

### Phase 3: E2E Validation (P0 E2E Tests)

18. E2E-002: Health check endpoint works

**Rationale:** Validate end-to-end flows

### Phase 4: Manual Critical Validation (P0 Manual)

19. MANUAL-001: Playwright browsers on all platforms
20. MANUAL-002: Compare mocks to real API docs
21. MANUAL-003: CI/CD <15 minutes
22. MANUAL-004: API response time baseline
23. MANUAL-007: New developer <10 minutes

**Rationale:** Human validation for cross-platform and performance

### Phase 5: P1 Tests (As Time Permits)

24. All P1 Integration tests (INT-004, INT-006, INT-009, etc.)
25. All P1 Unit tests (UNIT-004, UNIT-005, UNIT-008)
26. All P1 E2E tests (E2E-001, E2E-003)
27. P1 Manual (MANUAL-005)

### Phase 6: P2/P3 Tests (Nice to Have)

28. P2 tests (UNIT-007, INT-037, MANUAL-006)
29. P3 tests (INT-038)

---

## Coverage Gaps Analysis

**Analysis Result:** ✅ No coverage gaps identified

- Every AC has test coverage
- Every identified risk has mitigating tests
- Critical paths (framework setup, mock services, test environment) have multiple test levels
- Cross-platform validation explicitly included (MANUAL-001, MANUAL-005, MANUAL-007)
- Performance validation included (MANUAL-003, MANUAL-004)

---

## Test Maintainability Considerations

### Framework Tests (Lowest Maintenance)

- pytest, Vitest, Playwright tests are framework validation
- Low churn expected (frameworks stable)
- Update only when framework versions upgrade

### Mock Service Tests (Medium Maintenance)

- Mock LLM tests require updates when APIs change
- Monitor Claude API, OpenAI API for breaking changes
- Update fixtures when response formats evolve
- **Maintenance Trigger:** API version upgrades

### Test Fixture Tests (Medium-High Maintenance)

- Test database fixtures require updates when data models change
- Factory Boy reduces maintenance vs static fixtures
- **Maintenance Trigger:** Database schema migrations

### Environment Validation Tests (Low Maintenance)

- validate-setup.sh requires updates when tool versions change
- **Maintenance Trigger:** Tech stack version upgrades

### CI/CD Tests (Medium Maintenance)

- GitHub Actions workflows require updates when new tests added
- **Maintenance Trigger:** New test suites in future stories

---

## Test Data Requirements

### For Unit Tests

- Mock response fixtures (JSON files):
  - `tests/fixtures/llm/claude-completion.json`
  - `tests/fixtures/llm/claude-streaming.json`
  - `tests/fixtures/llm/openai-completion.json`
  - `tests/fixtures/llm/ollama-completion.json`
  - `tests/fixtures/mcp/file-sync-response.json`
  - `tests/fixtures/mcp/workflow-transition.json`

### For Integration Tests

- Test database fixtures (Factory Boy):
  - ClientFactory (5-10 sample clients)
  - ServiceFactory (3-5 services per client)
  - ProjectFactory (10-20 projects in various workflow states)
  - WorkflowStateFactory (samples for all BMAD stages)
  - DocumentFactory (10-15 sample documents with versions)

### For E2E Tests

- Minimal test data (created via API):
  - 1 client, 1 service, 1 project
  - Health check requires no data

### For Manual Tests

- Documentation artifacts:
  - Claude API documentation (link to official docs)
  - OpenAI API documentation (link to official docs)
  - OLLAMA API documentation (link to official docs)
  - Platform validation checklist (Windows WSL2, macOS, Linux)

---

## Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (integration-heavy for infrastructure)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention (1.5-LEVEL-###)
- [x] Scenarios are atomic and independent
- [x] Critical risks have multiple test scenarios
- [x] Cross-platform validation included
- [x] Performance validation included
- [x] Manual validation for circular dependency addressed

---

## Test Design Summary for Quality Gate

```yaml
test_design:
  scenarios_total: 45
  by_level:
    unit: 8
    integration: 27
    e2e: 3
    manual: 7
  by_priority:
    p0: 18
    p1: 15
    p2: 3
    p3: 1
  coverage_gaps: []
  risk_coverage: 100%
  ac_coverage: 100%
```

---

**Test Design Hook Line:**

```
Test design matrix: docs/qa/assessments/1.5-test-design-20250930.md
P0 tests identified: 18
```
